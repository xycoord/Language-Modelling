{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c04d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mech_interp import ToyModel\n",
    "from mech_interp.data_generators import SyntheticSparseDataGenerator\n",
    "from mech_interp.sparse_autoencoder import TopKSparseAutoencoder\n",
    "from mech_interp.script_utils import create_uniform_sparsity, create_importance\n",
    "from mech_interp.geometric_median import geometric_median\n",
    "from mech_interp.visualizations import plot_feature_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = 'toy_model_for_sae.pth'\n",
    "feature_dim = 5\n",
    "hidden_dim = 2\n",
    "sparsity = 0.9\n",
    "importance_decay = 0.9\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a84e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_sparsity = create_uniform_sparsity(feature_dim, sparsity)\n",
    "importance = create_importance(feature_dim, importance_decay)\n",
    "\n",
    "model = ToyModel(feature_dim, hidden_dim)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.requires_grad_(False)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a5ef73",
   "metadata": {},
   "source": [
    "\n",
    "# Setup SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1372538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect activations for SAE initialisation\n",
    "num_samples = 10_000\n",
    "sample_data = SyntheticSparseDataGenerator(\n",
    "                batch_size=num_samples,\n",
    "                sparsity=uniform_sparsity,\n",
    "                device=device\n",
    "                ).generate_batch()\n",
    "_, activations = model(sample_data)\n",
    "\n",
    "# Following the paper, we initialise the SAE bias as the geometric median of the activations.\n",
    "initial_sae_bias = geometric_median(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = TopKSparseAutoencoder(activations_dim=hidden_dim,\n",
    "                            feature_dim=feature_dim,\n",
    "                            initial_bias=initial_sae_bias,\n",
    "                            k=1\n",
    "                            ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_directions = sae.get_feature_directions().cpu()\n",
    "fig = plot_feature_directions(sae_directions, [\"SAE\"], importance, eps=3e-2)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036c2f6",
   "metadata": {},
   "source": [
    "# Train SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20_000\n",
    "plot_interval = 2500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 4096\n",
    "betas = (0.0, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10aa763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature_directions = model.get_feature_directions().cpu()\n",
    "feature_directions = [model_feature_directions]\n",
    "labels = ['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = SyntheticSparseDataGenerator(\n",
    "                batch_size=batch_size,\n",
    "                sparsity=uniform_sparsity,\n",
    "                device=device\n",
    "                )\n",
    "\n",
    "optimizer = torch.optim.Adam(sae.parameters(), lr=learning_rate, betas=betas)\n",
    "\n",
    "progress_bar = tqdm(range(iterations))\n",
    "for step in progress_bar:\n",
    "    if step % plot_interval == 0:\n",
    "        sae_directions = sae.get_feature_directions().cpu()\n",
    "        fig = plot_feature_directions(sae_directions, [\"SAE\"], importance, eps=3e-2)\n",
    "        fig.show()\n",
    "        feature_directions.append(sae.get_feature_directions().cpu())\n",
    "        labels.append(f'SAE@{step}')\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # Collect activations\n",
    "    batch = data_generator.generate_batch()\n",
    "    _, activations = model(batch)\n",
    "\n",
    "    reconstruction, features = sae(activations)\n",
    "\n",
    "    reconstruction_loss = F.mse_loss(activations, reconstruction)\n",
    "    loss = reconstruction_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    progress_bar.set_postfix(loss=f\"{loss.item():.3f}\", reconstruction_loss=f\"{reconstruction_loss.item():.3f}\")\n",
    "\n",
    "sae_directions = sae.get_feature_directions().cpu()\n",
    "fig = plot_feature_directions(sae_directions, [\"SAE\"], importance, eps=3e-2)\n",
    "fig.show()\n",
    "feature_directions.append(sae_directions)\n",
    "labels.append(f'SAE@{iterations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5167fae",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_directions = torch.stack(feature_directions, dim=0)\n",
    "fig = plot_feature_directions(feature_directions, labels, importance, eps=3e-2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
